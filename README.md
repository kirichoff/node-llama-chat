# node-llama-cpp chat

Simple chat with node llama
Meta-Llama-3.1-8B-Instruct.Q8_0 model by default

# About

research of [node-llama-cpp](https://github.com/withcatai/node-llama-cpp)
adapter for [llama.cpp](https://github.com/ggerganov/llama.cpp)
([c# adapter](https://github.com/SciSharp/LLamaSharp))

also check **node-llama-cpp** template

```bash
$ npm install node-llama-cpp@beta
```

```bash
$ npm create --yes node-llama-cpp@beta
```

[beta docks](https://github.com/withcatai/node-llama-cpp/pull/105)


## Project Setup

### Install

```bash
$ npm install
```

to pull model and deps

```bash
$ npm run postinstall
```

### Development

```bash
$ npm run dev
```

### Build

```bash
# For windows
$ npm run build:win

# For macOS
$ npm run build:mac

# For Linux
$ npm run build:linux
```
